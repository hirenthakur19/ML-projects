{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss, silhouette_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download the Anuran Calls (MFCCs) Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "      <th>Family</th>\n",
       "      <th>Genus</th>\n",
       "      <th>Species</th>\n",
       "      <th>RecordID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152936</td>\n",
       "      <td>-0.105586</td>\n",
       "      <td>0.200722</td>\n",
       "      <td>0.317201</td>\n",
       "      <td>0.260764</td>\n",
       "      <td>0.100945</td>\n",
       "      <td>-0.150063</td>\n",
       "      <td>-0.171128</td>\n",
       "      <td>0.124676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108351</td>\n",
       "      <td>-0.077623</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.057684</td>\n",
       "      <td>0.118680</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171534</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.268425</td>\n",
       "      <td>0.338672</td>\n",
       "      <td>0.268353</td>\n",
       "      <td>0.060835</td>\n",
       "      <td>-0.222475</td>\n",
       "      <td>-0.207693</td>\n",
       "      <td>0.170883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090974</td>\n",
       "      <td>-0.056510</td>\n",
       "      <td>-0.035303</td>\n",
       "      <td>0.020140</td>\n",
       "      <td>0.082263</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152317</td>\n",
       "      <td>-0.082973</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.276014</td>\n",
       "      <td>0.189867</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>-0.242234</td>\n",
       "      <td>-0.219153</td>\n",
       "      <td>0.232538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050691</td>\n",
       "      <td>-0.023590</td>\n",
       "      <td>-0.066722</td>\n",
       "      <td>-0.025083</td>\n",
       "      <td>0.099108</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224392</td>\n",
       "      <td>0.118985</td>\n",
       "      <td>0.329432</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>-0.194347</td>\n",
       "      <td>-0.098181</td>\n",
       "      <td>0.270375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.136009</td>\n",
       "      <td>-0.177037</td>\n",
       "      <td>-0.130498</td>\n",
       "      <td>-0.054766</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087817</td>\n",
       "      <td>-0.068345</td>\n",
       "      <td>0.306967</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.249144</td>\n",
       "      <td>0.006884</td>\n",
       "      <td>-0.265423</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>0.266434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048885</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.031346</td>\n",
       "      <td>0.108610</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>Leptodactylidae</td>\n",
       "      <td>Adenomera</td>\n",
       "      <td>AdenomeraAndre</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.554504</td>\n",
       "      <td>-0.337717</td>\n",
       "      <td>0.035533</td>\n",
       "      <td>0.034511</td>\n",
       "      <td>0.443451</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>-0.100753</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.081075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069430</td>\n",
       "      <td>0.071001</td>\n",
       "      <td>0.021591</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>-0.021860</td>\n",
       "      <td>-0.079860</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.517273</td>\n",
       "      <td>-0.370574</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068097</td>\n",
       "      <td>0.402890</td>\n",
       "      <td>0.096628</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.068978</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.101892</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.582557</td>\n",
       "      <td>-0.343237</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>0.064179</td>\n",
       "      <td>0.385596</td>\n",
       "      <td>0.114905</td>\n",
       "      <td>-0.103317</td>\n",
       "      <td>0.070370</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.077771</td>\n",
       "      <td>-0.009688</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>-0.080425</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.519497</td>\n",
       "      <td>-0.307553</td>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.072865</td>\n",
       "      <td>0.377131</td>\n",
       "      <td>0.086866</td>\n",
       "      <td>-0.115799</td>\n",
       "      <td>0.056979</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051796</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.017963</td>\n",
       "      <td>0.041803</td>\n",
       "      <td>-0.027911</td>\n",
       "      <td>-0.096895</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508833</td>\n",
       "      <td>-0.324106</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.397188</td>\n",
       "      <td>0.094596</td>\n",
       "      <td>-0.117672</td>\n",
       "      <td>0.058874</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>0.072983</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>-0.087910</td>\n",
       "      <td>Hylidae</td>\n",
       "      <td>Scinax</td>\n",
       "      <td>ScinaxRuber</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.152936 -0.105586  0.200722  0.317201  0.260764  0.100945   \n",
       "1          1.0  0.171534 -0.098975  0.268425  0.338672  0.268353  0.060835   \n",
       "2          1.0  0.152317 -0.082973  0.287128  0.276014  0.189867  0.008714   \n",
       "3          1.0  0.224392  0.118985  0.329432  0.372088  0.361005  0.015501   \n",
       "4          1.0  0.087817 -0.068345  0.306967  0.330923  0.249144  0.006884   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7190       1.0 -0.554504 -0.337717  0.035533  0.034511  0.443451  0.093889   \n",
       "7191       1.0 -0.517273 -0.370574  0.030673  0.068097  0.402890  0.096628   \n",
       "7192       1.0 -0.582557 -0.343237  0.029468  0.064179  0.385596  0.114905   \n",
       "7193       1.0 -0.519497 -0.307553 -0.004922  0.072865  0.377131  0.086866   \n",
       "7194       1.0 -0.508833 -0.324106  0.062068  0.078211  0.397188  0.094596   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_17  MFCCs_18  MFCCs_19  \\\n",
       "0    -0.150063 -0.171128  0.124676  ... -0.108351 -0.077623 -0.009568   \n",
       "1    -0.222475 -0.207693  0.170883  ... -0.090974 -0.056510 -0.035303   \n",
       "2    -0.242234 -0.219153  0.232538  ... -0.050691 -0.023590 -0.066722   \n",
       "3    -0.194347 -0.098181  0.270375  ... -0.136009 -0.177037 -0.130498   \n",
       "4    -0.265423 -0.172700  0.266434  ... -0.048885 -0.053074 -0.088550   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7190 -0.100753  0.037087  0.081075  ...  0.069430  0.071001  0.021591   \n",
       "7191 -0.116460  0.063727  0.089034  ...  0.061127  0.068978  0.017745   \n",
       "7192 -0.103317  0.070370  0.081317  ...  0.082474  0.077771 -0.009688   \n",
       "7193 -0.115799  0.056979  0.089316  ...  0.051796  0.069073  0.017963   \n",
       "7194 -0.117672  0.058874  0.076180  ...  0.061455  0.072983 -0.003980   \n",
       "\n",
       "      MFCCs_20  MFCCs_21  MFCCs_22           Family      Genus  \\\n",
       "0     0.057684  0.118680  0.014038  Leptodactylidae  Adenomera   \n",
       "1     0.020140  0.082263  0.029056  Leptodactylidae  Adenomera   \n",
       "2    -0.025083  0.099108  0.077162  Leptodactylidae  Adenomera   \n",
       "3    -0.054766 -0.018691  0.023954  Leptodactylidae  Adenomera   \n",
       "4    -0.031346  0.108610  0.079244  Leptodactylidae  Adenomera   \n",
       "...        ...       ...       ...              ...        ...   \n",
       "7190  0.052449 -0.021860 -0.079860          Hylidae     Scinax   \n",
       "7191  0.046461 -0.015418 -0.101892          Hylidae     Scinax   \n",
       "7192  0.027834 -0.000531 -0.080425          Hylidae     Scinax   \n",
       "7193  0.041803 -0.027911 -0.096895          Hylidae     Scinax   \n",
       "7194  0.031560 -0.029355 -0.087910          Hylidae     Scinax   \n",
       "\n",
       "             Species  RecordID  \n",
       "0     AdenomeraAndre         1  \n",
       "1     AdenomeraAndre         1  \n",
       "2     AdenomeraAndre         1  \n",
       "3     AdenomeraAndre         1  \n",
       "4     AdenomeraAndre         1  \n",
       "...              ...       ...  \n",
       "7190     ScinaxRuber        60  \n",
       "7191     ScinaxRuber        60  \n",
       "7192     ScinaxRuber        60  \n",
       "7193     ScinaxRuber        60  \n",
       "7194     ScinaxRuber        60  \n",
       "\n",
       "[7195 rows x 26 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Train a classifier for each label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Ratio: 0.972672533580361\n",
      "Hamming Score: 0.981318511656631\n",
      "Hamming Loss: 0.018681488343369\n"
     ]
    }
   ],
   "source": [
    "def exact_match_score(y_true, y_pred):\n",
    "    matches = np.all(y_true == y_pred, axis=1)\n",
    "    return np.mean(matches)\n",
    "\n",
    "def hamming_score(y_true, y_pred):\n",
    "    correct_labels = np.sum(y_true == y_pred)\n",
    "    total_labels = np.size(y_true)\n",
    "    return correct_labels / total_labels\n",
    "\n",
    "def hamming_loss_manual(y_true, y_pred):\n",
    " \n",
    "    incorrect_labels = np.sum(y_true != y_pred)\n",
    "    total_labels = np.size(y_true)\n",
    "    return incorrect_labels / total_labels\n",
    "\n",
    "df = pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "\n",
    "X = df.iloc[:, :-4].values  \n",
    "y = df.iloc[:, -4:-1]  \n",
    "\n",
    "label_encoders = {}\n",
    "for column in y.columns:\n",
    "    le = LabelEncoder()\n",
    "    y[column] = le.fit_transform(y[column])  \n",
    "    label_encoders[column] = le  \n",
    "\n",
    "y = y.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "classifiers = []\n",
    "y_pred = np.zeros_like(y_test)\n",
    "\n",
    "for i in range(y_train.shape[1]):  \n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train[:, i])  \n",
    "    classifiers.append(clf)\n",
    "    y_pred[:, i] = clf.predict(X_test)  \n",
    "\n",
    "\n",
    "exact_match = exact_match_score(y_test, y_pred)\n",
    "hamming_loss_value = hamming_loss_manual(y_test, y_pred)  \n",
    "hamming_score_value = hamming_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Exact Match Ratio: {exact_match:.15f}\")\n",
    "print(f\"Hamming Score: {hamming_score_value:.15f}\")\n",
    "print(f\"Hamming Loss: {hamming_loss_value:.15f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exact Match Ratio**\n",
    "\n",
    "\n",
    "Definition: The Exact Match Ratio measures the proportion of instances where all predicted labels exactly match all true labels. It’s the strictest evaluation metric for multi-label classification.\n",
    "\n",
    "**Hamming Score**\n",
    "\n",
    "\n",
    "Definition: The Hamming Score is the average accuracy of individual labels. It measures the fraction of correctly predicted labels (both positive and negative) across all labels and instances.\n",
    "\n",
    "\n",
    "**Hamming Loss**\n",
    "\n",
    "\n",
    "Definition: The Hamming Loss measures the fraction of incorrectly predicted labels across all instances. It quantifies the average mismatch between predicted and true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Train a SVM for each of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Hamming Loss: 0.0462\n",
      "Exact Match Ratio: 0.9254\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_performance(y_true, y_pred):\n",
    "    exact_matches = np.mean(np.all(y_true == y_pred, axis=1))\n",
    "    total_labels = y_true.size\n",
    "    incorrect_labels = np.sum(y_true != y_pred)\n",
    "    hamming = incorrect_labels / total_labels\n",
    "    return round(hamming, 4), round(exact_matches, 4)\n",
    "\n",
    "\n",
    "def wide_range_search(X_train, y_train, c_values, gamma_values, accuracy_threshold):\n",
    "    good_params = {'C': set(), 'gamma': set()}\n",
    "    for c in c_values:\n",
    "        for gamma in gamma_values:\n",
    "            accuracies = []\n",
    "            for i in range(y_train.shape[1]):\n",
    "                svc = SVC(kernel='rbf', C=c, gamma=gamma, random_state=42)\n",
    "                scores = cross_val_score(svc, X_train, y_train[:, i], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "                accuracies.append(scores.mean())\n",
    "            if np.mean(accuracies) >= accuracy_threshold:\n",
    "                good_params['C'].add(c)\n",
    "                good_params['gamma'].add(gamma)\n",
    "    \n",
    " \n",
    "    reduced_c_values = np.linspace(min(good_params['C']), max(good_params['C']), num=10)\n",
    "    reduced_gamma_values = np.linspace(min(good_params['gamma']), max(good_params['gamma']), num=10)\n",
    "    return {'C': reduced_c_values, 'gamma': reduced_gamma_values}\n",
    "\n",
    "\n",
    "\n",
    "def main_workflow():\n",
    "   \n",
    "    df = pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "    X = df.iloc[:, :-4].values\n",
    "    y = df.iloc[:, -4:-1]\n",
    "\n",
    "   \n",
    "    label_encoders = {}\n",
    "    for column in y.columns:\n",
    "        le = LabelEncoder()\n",
    "        y[column] = le.fit_transform(y[column])\n",
    "        label_encoders[column] = le\n",
    "    y = y.values\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_standardized = scaler.fit_transform(X_train)\n",
    "    X_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    c_values = [10**i for i in range(-3, 7)]\n",
    "    gamma_values = [i * 0.5 for i in range(1, 11)]\n",
    "    accuracy_threshold = 0.7\n",
    "    good_params = wide_range_search(X_train_standardized, y_train, c_values, gamma_values, accuracy_threshold)\n",
    "\n",
    "    \n",
    "    reduced_c_values = np.unique(good_params['C'])\n",
    "    reduced_gamma_values = np.unique(good_params['gamma'])\n",
    "    classifiers = []\n",
    "    y_pred = np.zeros_like(y_test)\n",
    "\n",
    "    for i in range(y_train.shape[1]):\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        for c in reduced_c_values:\n",
    "            for gamma in reduced_gamma_values:\n",
    "                svc = SVC(kernel='rbf', C=c, gamma=gamma, random_state=42)\n",
    "                scores = cross_val_score(svc, X_train_standardized, y_train[:, i], cv=5, scoring='accuracy', n_jobs=-1)\n",
    "                if scores.mean() > best_score:\n",
    "                    best_score = scores.mean()\n",
    "                    best_model = svc\n",
    "        best_model.fit(X_train_standardized, y_train[:, i])\n",
    "        classifiers.append(best_model)\n",
    "        y_pred[:, i] = best_model.predict(X_test_standardized)\n",
    "\n",
    "    \n",
    "    hamming, exact_match = evaluate_model_performance(y_test, y_pred)\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Hamming Loss: {hamming}\")\n",
    "    print(f\"Exact Match Ratio: {exact_match}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_workflow()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iii) Repeat 1(b)ii with L1-penalized SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for label 1/3...\n",
      "Best C for label 1: 1.0\n",
      "Training for label 2/3...\n",
      "Best C for label 2: 10.0\n",
      "Training for label 3/3...\n",
      "Best C for label 3: 10.0\n",
      "\n",
      "Results:\n",
      "Hamming Loss: 0.0568\n",
      "Exact Match Ratio: 0.9129\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_performance(y_true, y_pred):\n",
    "    exact_matches = np.mean(np.all(y_true == y_pred, axis=1))\n",
    "    total_labels = y_true.size\n",
    "    incorrect_labels = np.sum(y_true != y_pred)\n",
    "    hamming = incorrect_labels / total_labels\n",
    "    return round(hamming, 4), round(exact_matches, 4)\n",
    "\n",
    "\n",
    "def wide_range_search(X_train, y_train, c_values, accuracy_threshold):\n",
    "    good_params = {'C': []}\n",
    "    for c in c_values:\n",
    "        accuracies = []\n",
    "        for i in range(y_train.shape[1]):\n",
    "            lsvc = LinearSVC(penalty='l1', dual=False, C=c, max_iter=10000, random_state=42)\n",
    "            scores = cross_val_score(lsvc, X_train, y_train[:, i], cv=3, scoring='accuracy', n_jobs=-1)\n",
    "            accuracies.append(scores.mean())\n",
    "        if np.mean(accuracies) >= accuracy_threshold:\n",
    "            good_params['C'].append(c)\n",
    "    return good_params\n",
    "\n",
    "\n",
    "def main_workflow_l1():\n",
    "    \n",
    "    df = pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "    X = df.iloc[:, :-4].values\n",
    "    y = df.iloc[:, -4:-1]\n",
    "\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for column in y.columns:\n",
    "        le = LabelEncoder()\n",
    "        y[column] = le.fit_transform(y[column])\n",
    "        label_encoders[column] = le\n",
    "    y = y.values\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_standardized = scaler.fit_transform(X_train)\n",
    "    X_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "    c_values = [10**i for i in range(-3, 7)]  \n",
    "    accuracy_threshold = 0.7\n",
    "    good_params = wide_range_search(X_train_standardized, y_train, c_values, accuracy_threshold)\n",
    "\n",
    "    \n",
    "    reduced_c_values = np.logspace(np.log10(min(good_params['C'])), np.log10(max(good_params['C'])), num=10)\n",
    "\n",
    "    \n",
    "    param_grid = {'C': reduced_c_values}\n",
    "    classifiers = []\n",
    "    y_pred = np.zeros_like(y_test)\n",
    "\n",
    "    for i in range(y_train.shape[1]):\n",
    "        print(f\"Training for label {i+1}/{y_train.shape[1]}...\")\n",
    "        lsvc = LinearSVC(penalty='l1', dual=False, max_iter=10000, random_state=42)\n",
    "        grid_search = GridSearchCV(lsvc, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train_standardized, y_train[:, i])\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        classifiers.append(best_model)\n",
    "        y_pred[:, i] = best_model.predict(X_test_standardized)\n",
    "        \n",
    "        print(f\"Best C for label {i+1}: {grid_search.best_params_['C']}\")\n",
    "\n",
    "    \n",
    "    hamming, exact_match = evaluate_model_performance(y_test, y_pred)\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Hamming Loss: {hamming}\")\n",
    "    print(f\"Exact Match Ratio: {exact_match}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_workflow_l1()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (iv) Repeat 1(b)iii by using SMOTE or any other method for imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for label 1/3...\n",
      "Best C for label 1: 100.0\n",
      "Training for label 2/3...\n",
      "Best C for label 2: 100.0\n",
      "Training for label 3/3...\n",
      "Best C for label 3: 1000.0\n",
      "\n",
      "Results:\n",
      "Hamming Loss: 0.077\n",
      "Exact Match Ratio: 0.8532\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_performance(y_true, y_pred):\n",
    "    exact_matches = np.mean(np.all(y_true == y_pred, axis=1))\n",
    "    total_labels = y_true.size\n",
    "    incorrect_labels = np.sum(y_true != y_pred)\n",
    "    hamming = incorrect_labels / total_labels\n",
    "    return round(hamming, 4), round(exact_matches, 4)\n",
    "\n",
    "def wide_range_search(X_train, y_train, c_values, accuracy_threshold):\n",
    "    good_params = {'C': []}\n",
    "    for c in c_values:\n",
    "        accuracies = []\n",
    "        for i in range(y_train.shape[1]):\n",
    "            \n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_resampled, y_resampled = smote.fit_resample(X_train, y_train[:, i])\n",
    "\n",
    "            lsvc = LinearSVC(penalty='l1', dual=False, C=c, max_iter=10000, random_state=42)\n",
    "            scores = cross_val_score(lsvc, X_resampled, y_resampled, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "            accuracies.append(scores.mean())\n",
    "        if np.mean(accuracies) >= accuracy_threshold:\n",
    "            good_params['C'].append(c)\n",
    "    return good_params\n",
    "\n",
    "\n",
    "def main_workflow_l1_smote():\n",
    "   \n",
    "    df = pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "    X = df.iloc[:, :-4].values\n",
    "    y = df.iloc[:, -4:-1]\n",
    "\n",
    "    \n",
    "    label_encoders = {}\n",
    "    for column in y.columns:\n",
    "        le = LabelEncoder()\n",
    "        y[column] = le.fit_transform(y[column])\n",
    "        label_encoders[column] = le\n",
    "    y = y.values\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "   \n",
    "    scaler = StandardScaler()\n",
    "    X_train_standardized = scaler.fit_transform(X_train)\n",
    "    X_test_standardized = scaler.transform(X_test)\n",
    "\n",
    "   \n",
    "    c_values = [10**i for i in range(-3, 7)]  \n",
    "    accuracy_threshold = 0.7\n",
    "    good_params = wide_range_search(X_train_standardized, y_train, c_values, accuracy_threshold)\n",
    "\n",
    "    \n",
    "    reduced_c_values = np.logspace(np.log10(min(good_params['C'])), np.log10(max(good_params['C'])), num=10)\n",
    "\n",
    "    \n",
    "    param_grid = {'C': reduced_c_values}\n",
    "    classifiers = []\n",
    "    y_pred = np.zeros_like(y_test)\n",
    "\n",
    "    for i in range(y_train.shape[1]):\n",
    "        print(f\"Training for label {i+1}/{y_train.shape[1]}...\")\n",
    "\n",
    "       \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train_standardized, y_train[:, i])\n",
    "\n",
    "        \n",
    "        lsvc = LinearSVC(penalty='l1', dual=False, max_iter=10000, random_state=42)\n",
    "        grid_search = GridSearchCV(lsvc, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "        best_model = grid_search.best_estimator_\n",
    "        classifiers.append(best_model)\n",
    "        y_pred[:, i] = best_model.predict(X_test_standardized)\n",
    "\n",
    "        print(f\"Best C for label {i+1}: {grid_search.best_params_['C']}\")\n",
    "\n",
    "    \n",
    "    hamming, exact_match = evaluate_model_performance(y_test, y_pred)\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Hamming Loss: {hamming}\")\n",
    "    print(f\"Exact Match Ratio: {exact_match}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_workflow_l1_smote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Means Clustering on a Multi-Class and Multi-Label Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Use k-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters (k): 4\n",
      "K-means clustering completed with 4 clusters.\n"
     ]
    }
   ],
   "source": [
    "def find_optimal_k(X, max_k=50):\n",
    "    silhouette_scores = []\n",
    "    for k in range(2, max_k + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(X)\n",
    "        silhouette_scores.append(silhouette_score(X, labels))\n",
    "    optimal_k = np.argmax(silhouette_scores) + 2\n",
    "    return optimal_k, silhouette_scores\n",
    "\n",
    "\n",
    "def encode_labels(y):\n",
    "    encoders = []\n",
    "    y_encoded = np.zeros_like(y)\n",
    "    for i in range(y.shape[1]):\n",
    "        encoder = LabelEncoder()\n",
    "        y_encoded[:, i] = encoder.fit_transform(y[:, i])\n",
    "        encoders.append(encoder)\n",
    "    return y_encoded, encoders\n",
    "\n",
    "\n",
    "def find_majority_class(cluster_df, label_column):\n",
    "    majority_classes = {}\n",
    "    for cluster in cluster_df['Cluster'].unique():\n",
    "        cluster_data = cluster_df[cluster_df['Cluster'] == cluster]\n",
    "        majority_class = Counter(cluster_data[label_column]).most_common(1)[0][0]\n",
    "        majority_classes[cluster] = majority_class\n",
    "    return majority_classes\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/Anuran Calls (MFCCs)/Frogs_MFCCs.csv')\n",
    "X = df.iloc[:, :-4].values  \n",
    "y = df.iloc[:, -4:-1].values  \n",
    "\n",
    "\n",
    "y_encoded, encoders = encode_labels(y)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "optimal_k, silhouette_scores = find_optimal_k(X_standardized)\n",
    "print(f\"Optimal number of clusters (k): {optimal_k}\")\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df['Cluster'] = kmeans.fit_predict(X_standardized)  \n",
    "print(f\"K-means clustering completed with {optimal_k} clusters.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Determine which family is the majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Majority Family in each cluster:\n",
      "{0: 'Hylidae', 2: 'Hylidae', 3: 'Leptodactylidae', 1: 'Leptodactylidae'}\n",
      "\n",
      "Majority Genus in each cluster:\n",
      "{0: 'Hypsiboas', 2: 'Hypsiboas', 3: 'Adenomera', 1: 'Adenomera'}\n",
      "\n",
      "Majority Species in each cluster:\n",
      "{0: 'HypsiboasCordobae', 2: 'HypsiboasCinerascens', 3: 'AdenomeraAndre', 1: 'AdenomeraHylaedactylus'}\n"
     ]
    }
   ],
   "source": [
    "majority_family = find_majority_class(df, 'Family')\n",
    "majority_genus = find_majority_class(df, 'Genus')\n",
    "majority_species = find_majority_class(df, 'Species')\n",
    "\n",
    "# Step 4: Print results\n",
    "print(\"\\nMajority Family in each cluster:\")\n",
    "print(majority_family)\n",
    "\n",
    "print(\"\\nMajority Genus in each cluster:\")\n",
    "print(majority_genus)\n",
    "\n",
    "print(\"\\nMajority Species in each cluster:\")\n",
    "print(majority_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Family in each cluster:\n",
      "{0: 'Hylidae', 2: 'Hylidae', 3: 'Leptodactylidae', 1: 'Leptodactylidae'}\n",
      "\n",
      "Majority Genus in each cluster:\n",
      "{0: 'Hypsiboas', 2: 'Hypsiboas', 3: 'Adenomera', 1: 'Adenomera'}\n",
      "\n",
      "Majority Species in each cluster:\n",
      "{0: 'HypsiboasCordobae', 2: 'HypsiboasCinerascens', 3: 'AdenomeraAndre', 1: 'AdenomeraHylaedactylus'}\n"
     ]
    }
   ],
   "source": [
    "def find_majority_class(cluster_df, label_column):\n",
    "    majority_classes = {}\n",
    "    for cluster in cluster_df['Cluster'].unique():\n",
    "        cluster_data = cluster_df[cluster_df['Cluster'] == cluster]\n",
    "        majority_class = Counter(cluster_data[label_column]).most_common(1)[0][0]\n",
    "        majority_classes[cluster] = majority_class\n",
    "    return majority_classes\n",
    "\n",
    "\n",
    "majority_family = find_majority_class(df, 'Family')\n",
    "majority_genus = find_majority_class(df, 'Genus')\n",
    "majority_species = find_majority_class(df, 'Species')\n",
    "\n",
    "# Print results\n",
    "print(\"Majority Family in each cluster:\")\n",
    "print(majority_family)\n",
    "\n",
    "print(\"\\nMajority Genus in each cluster:\")\n",
    "print(majority_genus)\n",
    "\n",
    "print(\"\\nMajority Species in each cluster:\")\n",
    "print(majority_species)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Monte Carlo Simulation Results:\n",
      "Average Hamming Distance: 0.2434\n",
      "Standard Deviation of Hamming Distance: 0.0089\n"
     ]
    }
   ],
   "source": [
    "def monte_carlo_simulation(X, y, k, num_iterations=50):\n",
    "    hamming_distances = []\n",
    "    for _ in range(num_iterations):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=None, n_init=10)\n",
    "        predicted_clusters = kmeans.fit_predict(X)\n",
    "        \n",
    "        distance = calculate_hamming_distance(y, predicted_clusters)\n",
    "        hamming_distances.append(distance)\n",
    "    return np.mean(hamming_distances), np.std(hamming_distances)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_hamming_distance(true_labels, predicted_labels):\n",
    "    mapped_labels = np.zeros_like(true_labels)  \n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = predicted_labels == cluster\n",
    "        cluster_labels = true_labels[mask]\n",
    "\n",
    "        if len(cluster_labels) > 0:\n",
    "            cluster_labels = cluster_labels.astype(int)  \n",
    "            cluster_modes = [mode(cluster_labels[:, i], keepdims=True).mode[0] for i in range(cluster_labels.shape[1])]\n",
    "\n",
    "           \n",
    "            for i in range(cluster_labels.shape[1]):\n",
    "                mapped_labels[mask, i] = cluster_modes[i]\n",
    "\n",
    "    \n",
    "    return np.mean(true_labels != mapped_labels)\n",
    "\n",
    "mean_hamming, std_hamming = monte_carlo_simulation(X_standardized, y_encoded, optimal_k)\n",
    "print(f\"\\nMonte Carlo Simulation Results:\")\n",
    "print(f\"Average Hamming Distance: {mean_hamming:.4f}\")\n",
    "print(f\"Standard Deviation of Hamming Distance: {std_hamming:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Calculate the average Hamming distance, Hamming score, and Hamming loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Distance: 5021\n",
      "Hamming Score: 0.7674\n",
      "Hamming Loss: 0.2326\n"
     ]
    }
   ],
   "source": [
    "def assign_majority_labels(df, majority_family, majority_genus, majority_species):\n",
    "    \n",
    "    df['Assigned_Family'] = df['Cluster'].map(majority_family)\n",
    "    df['Assigned_Genus'] = df['Cluster'].map(majority_genus)\n",
    "    df['Assigned_Species'] = df['Cluster'].map(majority_species)\n",
    "    return df\n",
    "\n",
    "def calculate_hamming_metrics(df, true_labels):\n",
    "   \n",
    "    assigned_labels = df[['Assigned_Family', 'Assigned_Genus', 'Assigned_Species']].values\n",
    "    \n",
    "    \n",
    "    hamming_distance = np.sum(true_labels != assigned_labels)\n",
    "    \n",
    "   \n",
    "    total_labels = true_labels.size\n",
    "    \n",
    "    \n",
    "    hamming_loss_value = hamming_distance / total_labels\n",
    "    \n",
    "   \n",
    "    hamming_score = 1 - hamming_loss_value\n",
    "    \n",
    "    return hamming_distance, hamming_score, hamming_loss_value\n",
    "\n",
    "\n",
    "df = assign_majority_labels(df, majority_family, majority_genus, majority_species)\n",
    "\n",
    "\n",
    "true_labels = y \n",
    "hamming_distance, hamming_score, hamming_loss_value = calculate_hamming_metrics(df, true_labels)\n",
    "\n",
    "\n",
    "print(f\"Hamming Distance: {hamming_distance}\")\n",
    "print(f\"Hamming Score: {hamming_score:.4f}\")\n",
    "print(f\"Hamming Loss: {hamming_loss_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.hamming_loss.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html\n",
    "\n",
    "https://www.kdnuggets.com/hyperparameter-tuning-gridsearchcv-and-randomizedsearchcv-explained\n",
    "\n",
    "https://mmuratarat.github.io/2020-01-25/multilabel_classification_metrics\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/svm/plot_svm_scale_c.html\n",
    "\n",
    "https://arxiv.org/abs/1106.1813\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/multiclass.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/miscellaneous/plot_multilabel.html\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/\n",
    "\n",
    "https://naeglelab.github.io/OpenEnsembles/Examples/Example_Kmeans_MajorityVote.html\n",
    "\n",
    "https://scikit-learn.org/1.5/modules/generated/sklearn.cluster.KMeans.html\n",
    "\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.metrics.silhouette_score.html\n",
    "\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n",
    "\n",
    "https://docs.python.org/3/library/collections.html#collections.Counter\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
