{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Thakur_Hiren_HW3</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Hiren Thakur\n",
    "<br>\n",
    "Github Username: hirenthakur\n",
    "<br>\n",
    "USC ID: 9304219569"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import bootstrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloaded the dataset and uploaded in github data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Sample:\n",
      "   # Columns: time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
      "0                0      42.00       0.71      21.25       0.43      30.00   \n",
      "1              250      41.50       0.50      20.25       1.48      31.25   \n",
      "2              500      41.50       0.50      14.25       1.92      33.00   \n",
      "3              750      40.75       0.83      15.75       0.43      33.00   \n",
      "4             1000      40.00       0.71      20.00       2.74      32.75   \n",
      "\n",
      "   var_rss23  \n",
      "0       0.00  \n",
      "1       1.09  \n",
      "2       0.00  \n",
      "3       0.00  \n",
      "4       0.43  \n",
      "\n",
      "Test Data Sample:\n",
      "   # Columns: time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
      "0                0      39.25       0.43      22.75       0.43      33.75   \n",
      "1              250      39.25       0.43      23.00       0.00      33.00   \n",
      "2              500      39.25       0.43      23.25       0.43      33.00   \n",
      "3              750      39.50       0.50      23.00       0.71      33.00   \n",
      "4             1000      39.50       0.50      24.00       0.00      33.00   \n",
      "\n",
      "   var_rss23  \n",
      "0        1.3  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n"
     ]
    }
   ],
   "source": [
    "def split_train_test_data(base_path):\n",
    "  \n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "       \n",
    "    activity_folders = [folder for folder in os.listdir(base_path) if 'pdf' not in folder]\n",
    "\n",
    "    for activity in activity_folders:\n",
    "        activity_path = os.path.join(base_path, activity)\n",
    "        activity_files = os.listdir(activity_path)\n",
    "\n",
    "  \n",
    "        if activity in ['bending1', 'bending2']:\n",
    "            for file in activity_files:\n",
    "                file_path = os.path.join(activity_path, file)\n",
    "                data = pd.read_csv(file_path, skiprows=4, usecols=range(7))\n",
    "\n",
    "                \n",
    "                if file in ['dataset1.csv', 'dataset2.csv']:\n",
    "                    test_data = pd.concat([test_data, data], ignore_index=True)\n",
    "                else:\n",
    "                    train_data = pd.concat([train_data, data], ignore_index=True)\n",
    "\n",
    "        \n",
    "        else:\n",
    "            for file in activity_files:\n",
    "                file_path = os.path.join(activity_path, file)\n",
    "                data = pd.read_csv(file_path, skiprows=4, usecols=range(7))\n",
    "\n",
    "            \n",
    "                if file in ['dataset1.csv', 'dataset2.csv', 'dataset3.csv']:\n",
    "                    test_data = pd.concat([test_data, data], ignore_index=True)\n",
    "                else:\n",
    "                    train_data = pd.concat([train_data, data], ignore_index=True)\n",
    "\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "base_path = \"../data/AReM/\"\n",
    "train_df, test_df = split_train_test_data(base_path)\n",
    "\n",
    "\n",
    "print(\"Training Data Sample:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest Data Sample:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean: The average value of the time series, providing information on the overall trend or central tendency of the data.\n",
    "\n",
    "Median: The middle value of the ordered data points, offering a measure of central tendency that is less affected by outliers compared to the mean.\n",
    "\n",
    "Minimum: The smallest value in the time series, giving insight into the lower bound of the data's amplitude.\n",
    "\n",
    "Maximum: The largest value in the time series, showing the upper bound of the data's amplitude.\n",
    "\n",
    "Standard Deviation: Measures the amount of variation or dispersion from the mean, indicating how spread out the time series values are.\n",
    "\n",
    "Variance: The square of the standard deviation, representing the spread of the data. High variance indicates a wide range of values.\n",
    "\n",
    "Range: The difference between the maximum and minimum values, describing the amplitude range of the signal.\n",
    "\n",
    "Skewness: A measure of the asymmetry of the data distribution. Positive skewness means the tail on the right side is longer, while negative skewness indicates a longer left tail.\n",
    "\n",
    "Kurtosis: Describes the \"tailedness\" of the distribution. A high kurtosis means there are more extreme values, and low kurtosis indicates a more uniform distribution.\n",
    "\n",
    "Root Mean Square (RMS): The square root of the mean of the squared values, useful for quantifying the magnitude of the time series signal.\n",
    "Autocorrelation: Measures how related the time series is to a lagged version of itself. It helps detect periodic patterns or the regularity of the signal.\n",
    "\n",
    "Energy: The sum of the squared values of the time series, representing the signal's total power.\n",
    "\n",
    "Entropy: A measure of complexity or unpredictability in the time series, with higher entropy indicating more disorder.\n",
    "\n",
    "Zero-Crossing Rate: The rate at which the time series crosses the zero-value line. It can be useful for identifying changes in the signal or oscillations.\n",
    "\n",
    "Absolute Sum of Changes: The sum of the absolute differences between consecutive values, indicating the amount of variability or smoothness in the signal.\n",
    "\n",
    "Interquartile Range (IQR): The difference between the 75th and 25th percentiles of the data, providing a measure of the spread of the central 50% of values.\n",
    "\n",
    "Signal Magnitude Area (SMA): The sum of the absolute values of the signal, often used in activity recognition to measure overall signal strength.\n",
    "\n",
    "Peak-to-Peak Amplitude: The difference between the maximum and minimum peak values in the time series, indicating the signal's oscillation range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min1</th>\n",
       "      <th>max1</th>\n",
       "      <th>mean1</th>\n",
       "      <th>median1</th>\n",
       "      <th>std_dev1</th>\n",
       "      <th>1st_quartile1</th>\n",
       "      <th>3rd_quartile1</th>\n",
       "      <th>min2</th>\n",
       "      <th>max2</th>\n",
       "      <th>mean2</th>\n",
       "      <th>...</th>\n",
       "      <th>std_dev5</th>\n",
       "      <th>1st_quartile5</th>\n",
       "      <th>3rd_quartile5</th>\n",
       "      <th>min6</th>\n",
       "      <th>max6</th>\n",
       "      <th>mean6</th>\n",
       "      <th>median6</th>\n",
       "      <th>std_dev6</th>\n",
       "      <th>1st_quartile6</th>\n",
       "      <th>3rd_quartile6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.25</td>\n",
       "      <td>45.00</td>\n",
       "      <td>40.624792</td>\n",
       "      <td>40.500</td>\n",
       "      <td>1.476967</td>\n",
       "      <td>39.25</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.358604</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188449</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0.570583</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.00</td>\n",
       "      <td>45.67</td>\n",
       "      <td>42.812812</td>\n",
       "      <td>42.500</td>\n",
       "      <td>1.435550</td>\n",
       "      <td>42.00</td>\n",
       "      <td>43.6700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.372437</td>\n",
       "      <td>...</td>\n",
       "      <td>1.995255</td>\n",
       "      <td>32.0000</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.601010</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.00</td>\n",
       "      <td>47.40</td>\n",
       "      <td>43.954500</td>\n",
       "      <td>44.330</td>\n",
       "      <td>1.558835</td>\n",
       "      <td>43.00</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.999604</td>\n",
       "      <td>35.3625</td>\n",
       "      <td>36.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.513506</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.00</td>\n",
       "      <td>47.75</td>\n",
       "      <td>42.179812</td>\n",
       "      <td>43.500</td>\n",
       "      <td>3.670666</td>\n",
       "      <td>39.15</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.696042</td>\n",
       "      <td>...</td>\n",
       "      <td>3.849448</td>\n",
       "      <td>30.4575</td>\n",
       "      <td>36.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.613521</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.524317</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33.00</td>\n",
       "      <td>45.75</td>\n",
       "      <td>41.678063</td>\n",
       "      <td>41.750</td>\n",
       "      <td>2.243490</td>\n",
       "      <td>41.33</td>\n",
       "      <td>42.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>...</td>\n",
       "      <td>2.411026</td>\n",
       "      <td>28.4575</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.383292</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.389164</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>20.75</td>\n",
       "      <td>46.25</td>\n",
       "      <td>34.763333</td>\n",
       "      <td>35.290</td>\n",
       "      <td>4.742208</td>\n",
       "      <td>31.67</td>\n",
       "      <td>38.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.68</td>\n",
       "      <td>4.223792</td>\n",
       "      <td>...</td>\n",
       "      <td>3.174681</td>\n",
       "      <td>14.2500</td>\n",
       "      <td>18.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.39</td>\n",
       "      <td>3.288271</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.647528</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>21.50</td>\n",
       "      <td>51.00</td>\n",
       "      <td>34.935812</td>\n",
       "      <td>35.500</td>\n",
       "      <td>4.645944</td>\n",
       "      <td>32.00</td>\n",
       "      <td>38.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.21</td>\n",
       "      <td>4.115750</td>\n",
       "      <td>...</td>\n",
       "      <td>3.192058</td>\n",
       "      <td>14.2375</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.21</td>\n",
       "      <td>3.280021</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.700918</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>18.33</td>\n",
       "      <td>47.67</td>\n",
       "      <td>34.333042</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.948770</td>\n",
       "      <td>31.25</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.48</td>\n",
       "      <td>4.396958</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000493</td>\n",
       "      <td>13.7500</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.01</td>\n",
       "      <td>3.261583</td>\n",
       "      <td>2.980</td>\n",
       "      <td>1.617290</td>\n",
       "      <td>2.05</td>\n",
       "      <td>4.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>18.33</td>\n",
       "      <td>45.75</td>\n",
       "      <td>34.599875</td>\n",
       "      <td>35.125</td>\n",
       "      <td>4.731790</td>\n",
       "      <td>31.50</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.37</td>\n",
       "      <td>4.398833</td>\n",
       "      <td>...</td>\n",
       "      <td>2.905688</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.86</td>\n",
       "      <td>3.289542</td>\n",
       "      <td>3.015</td>\n",
       "      <td>1.680170</td>\n",
       "      <td>2.12</td>\n",
       "      <td>4.2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>15.50</td>\n",
       "      <td>43.67</td>\n",
       "      <td>34.225875</td>\n",
       "      <td>34.750</td>\n",
       "      <td>4.441798</td>\n",
       "      <td>31.25</td>\n",
       "      <td>37.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.24</td>\n",
       "      <td>4.354500</td>\n",
       "      <td>...</td>\n",
       "      <td>2.992920</td>\n",
       "      <td>14.3300</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.42</td>\n",
       "      <td>3.479542</td>\n",
       "      <td>3.270</td>\n",
       "      <td>1.761146</td>\n",
       "      <td>2.24</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     min1   max1      mean1  median1  std_dev1  1st_quartile1  3rd_quartile1  \\\n",
       "1   37.25  45.00  40.624792   40.500  1.476967          39.25        42.0000   \n",
       "2   38.00  45.67  42.812812   42.500  1.435550          42.00        43.6700   \n",
       "3   35.00  47.40  43.954500   44.330  1.558835          43.00        45.0000   \n",
       "4   33.00  47.75  42.179812   43.500  3.670666          39.15        45.0000   \n",
       "5   33.00  45.75  41.678063   41.750  2.243490          41.33        42.7500   \n",
       "..    ...    ...        ...      ...       ...            ...            ...   \n",
       "84  20.75  46.25  34.763333   35.290  4.742208          31.67        38.2500   \n",
       "85  21.50  51.00  34.935812   35.500  4.645944          32.00        38.0625   \n",
       "86  18.33  47.67  34.333042   34.750  4.948770          31.25        38.0000   \n",
       "87  18.33  45.75  34.599875   35.125  4.731790          31.50        38.0000   \n",
       "88  15.50  43.67  34.225875   34.750  4.441798          31.25        37.2500   \n",
       "\n",
       "    min2   max2     mean2  ...  std_dev5  1st_quartile5  3rd_quartile5  min6  \\\n",
       "1    0.0   1.30  0.358604  ...  2.188449        33.0000          36.00   0.0   \n",
       "2    0.0   1.22  0.372437  ...  1.995255        32.0000          34.50   0.0   \n",
       "3    0.0   1.70  0.426250  ...  1.999604        35.3625          36.50   0.0   \n",
       "4    0.0   3.00  0.696042  ...  3.849448        30.4575          36.33   0.0   \n",
       "5    0.0   2.83  0.535979  ...  2.411026        28.4575          31.25   0.0   \n",
       "..   ...    ...       ...  ...       ...            ...            ...   ...   \n",
       "84   0.0  12.68  4.223792  ...  3.174681        14.2500          18.33   0.0   \n",
       "85   0.0  12.21  4.115750  ...  3.192058        14.2375          18.25   0.0   \n",
       "86   0.0  12.48  4.396958  ...  3.000493        13.7500          18.00   0.0   \n",
       "87   0.0  15.37  4.398833  ...  2.905688        14.0000          18.25   0.0   \n",
       "88   0.0  17.24  4.354500  ...  2.992920        14.3300          18.25   0.0   \n",
       "\n",
       "     max6     mean6  median6  std_dev6  1st_quartile6  3rd_quartile6  \n",
       "1    1.92  0.570583    0.430  0.582915           0.00         1.3000  \n",
       "2    3.11  0.571083    0.430  0.601010           0.00         1.3000  \n",
       "3    1.79  0.493292    0.430  0.513506           0.00         0.9400  \n",
       "4    2.18  0.613521    0.500  0.524317           0.00         1.0000  \n",
       "5    1.79  0.383292    0.430  0.389164           0.00         0.5000  \n",
       "..    ...       ...      ...       ...            ...            ...  \n",
       "84   9.39  3.288271    3.270  1.647528           2.05         4.3050  \n",
       "85  10.21  3.280021    3.015  1.700918           2.12         4.5000  \n",
       "86   8.01  3.261583    2.980  1.617290           2.05         4.3200  \n",
       "87   8.86  3.289542    3.015  1.680170           2.12         4.2600  \n",
       "88   9.42  3.479542    3.270  1.761146           2.24         4.5375  \n",
       "\n",
       "[88 rows x 42 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_time_series_data(folder_path):\n",
    "    time_series_data = []\n",
    "\n",
    "    def read_csv(file, path):\n",
    "        return pd.read_csv(os.path.join(path, file), skiprows=4, usecols=range(1, 7))\n",
    "\n",
    "    for directory in filter(lambda x: 'pdf' not in x, os.listdir(folder_path)):\n",
    "        complete_path = os.path.join(folder_path, directory)\n",
    "        csv_files = filter(lambda f: f.endswith('.csv'), os.listdir(complete_path))\n",
    "\n",
    "        time_series_data.extend(map(lambda file: read_csv(file, complete_path), csv_files))\n",
    "\n",
    "    return time_series_data\n",
    "\n",
    "stats_features = ['min', 'max', 'mean', 'median', 'std_dev', '1st_quartile', '3rd_quartile']\n",
    "\n",
    "data_columns = [f\"{feature}{i}\" for i in range(1, 7) for feature in stats_features]\n",
    "\n",
    "DATA_PATH = \"../data/AReM/\"\n",
    "\n",
    "loaded_time_series = fetch_time_series_data(DATA_PATH)\n",
    "\n",
    "rows_of_features = []\n",
    "\n",
    "for data in loaded_time_series:\n",
    "    statistics = data.describe()\n",
    "    row_data = []\n",
    "\n",
    "    for i in range(6):\n",
    "        row_data.extend([\n",
    "            statistics.iloc[3, i],  \n",
    "            statistics.iloc[7, i],  \n",
    "            statistics.iloc[1, i],  \n",
    "            statistics.iloc[5, i],  \n",
    "            statistics.iloc[2, i],  \n",
    "            statistics.iloc[4, i],  \n",
    "            statistics.iloc[6, i]   \n",
    "        ])\n",
    "    \n",
    "    rows_of_features.append(row_data)\n",
    "\n",
    "df_features = pd.DataFrame(rows_of_features, columns=data_columns)\n",
    "\n",
    "df_features.index = df_features.index + 1\n",
    "\n",
    "df_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of min1: 9.569975284512807\n",
      "Standard deviation of max1: 4.39436168470319\n",
      "Standard deviation of mean1: 5.3357176583441746\n",
      "Standard deviation of median1: 5.440054137152637\n",
      "Standard deviation of std_dev1: 1.772153397502841\n",
      "Standard deviation of 1st_quartile1: 6.1535897241853705\n",
      "Standard deviation of 3rd_quartile1: 5.138924613450999\n",
      "Standard deviation of min2: 0.0\n",
      "Standard deviation of max2: 5.0627293748106394\n",
      "Standard deviation of mean2: 1.5741639200745141\n",
      "Standard deviation of median2: 1.4122441649745636\n",
      "Standard deviation of std_dev2: 0.8841054781862713\n",
      "Standard deviation of 1st_quartile2: 0.9463861911256928\n",
      "Standard deviation of 3rd_quartile2: 2.12526640640591\n",
      "Standard deviation of min3: 2.956462059205819\n",
      "Standard deviation of max3: 4.875136693954745\n",
      "Standard deviation of mean3: 4.008380131777648\n",
      "Standard deviation of median3: 4.036396318784075\n",
      "Standard deviation of std_dev3: 0.9467102620752954\n",
      "Standard deviation of 1st_quartile3: 4.22065788450763\n",
      "Standard deviation of 3rd_quartile3: 4.171628224016796\n",
      "Standard deviation of min4: 0.0\n",
      "Standard deviation of max4: 2.1836254849723407\n",
      "Standard deviation of mean4: 1.166114090919611\n",
      "Standard deviation of median4: 1.1455856609880564\n",
      "Standard deviation of std_dev4: 0.45824169747631166\n",
      "Standard deviation of 1st_quartile4: 0.8436196840035469\n",
      "Standard deviation of 3rd_quartile4: 1.5525041782503675\n",
      "Standard deviation of min5: 6.124001430553483\n",
      "Standard deviation of max5: 5.741238300951952\n",
      "Standard deviation of mean5: 5.675593204313177\n",
      "Standard deviation of median5: 5.813782436530036\n",
      "Standard deviation of std_dev5: 1.0248979053506881\n",
      "Standard deviation of 1st_quartile5: 6.096465201564951\n",
      "Standard deviation of 3rd_quartile5: 5.531720219299494\n",
      "Standard deviation of min6: 0.045838154016456245\n",
      "Standard deviation of max6: 2.5189209776905526\n",
      "Standard deviation of mean6: 1.1548119239544565\n",
      "Standard deviation of median6: 1.0864743253475888\n",
      "Standard deviation of std_dev6: 0.517617474590413\n",
      "Standard deviation of 1st_quartile6: 0.7585838153286205\n",
      "Standard deviation of 3rd_quartile6: 1.5235991261756407\n"
     ]
    }
   ],
   "source": [
    "def calculate_std(data):\n",
    "    return np.std(data, ddof=1)\n",
    "\n",
    "def bootstrap_ci(data, num_iterations=1000, ci=90):\n",
    "    n = len(data)\n",
    "    bootstrap_samples = np.random.choice(data, (num_iterations, n), replace=True)\n",
    "    bootstrap_statistics = np.std(bootstrap_samples, axis=1, ddof=1)\n",
    "    \n",
    "    lower_bound = (100 - ci) / 2\n",
    "    upper_bound = 100 - lower_bound\n",
    "    ci_lower = np.percentile(bootstrap_statistics, lower_bound)\n",
    "    ci_upper = np.percentile(bootstrap_statistics, upper_bound)\n",
    "    \n",
    "    return ci_lower, ci_upper\n",
    "\n",
    "bootstrap_intervals = {}\n",
    "\n",
    "for feature in df_features.columns:\n",
    "    data = df_features[feature].values\n",
    "    \n",
    "    std_value = calculate_std(data)\n",
    "    print(f\"Standard deviation of {feature}: {std_value}\")\n",
    "    \n",
    "    lower_ci, upper_ci = bootstrap_ci(data)\n",
    "    bootstrap_intervals[feature] = (lower_ci, upper_ci)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90% CI for the standard deviation of min1: (8.26181150981084, 10.794370722608141)\n",
      "90% CI for the standard deviation of max1: (3.387482764699266, 5.287967893457751)\n",
      "90% CI for the standard deviation of mean1: (4.709953295616737, 5.8948303320218045)\n",
      "90% CI for the standard deviation of median1: (4.782114701904006, 5.9483679430083445)\n",
      "90% CI for the standard deviation of std_dev1: (1.5830345996593709, 1.9508023414834197)\n",
      "90% CI for the standard deviation of 1st_quartile1: (5.583932701539521, 6.651039747083147)\n",
      "90% CI for the standard deviation of 3rd_quartile1: (4.355384854379679, 5.8372320022459485)\n",
      "90% CI for the standard deviation of min2: (0.0, 0.0)\n",
      "90% CI for the standard deviation of max2: (4.637126039937011, 5.405852542496656)\n",
      "90% CI for the standard deviation of mean2: (1.3861916366800298, 1.7004174060119293)\n",
      "90% CI for the standard deviation of median2: (1.2318982106398386, 1.5522980057122957)\n",
      "90% CI for the standard deviation of std_dev2: (0.8008751336466153, 0.9406821718754274)\n",
      "90% CI for the standard deviation of 1st_quartile2: (0.8252846562222864, 1.0326133568967222)\n",
      "90% CI for the standard deviation of 3rd_quartile2: (1.896915147668951, 2.3008959514453884)\n",
      "90% CI for the standard deviation of min3: (2.7576837324258223, 3.115317783206396)\n",
      "90% CI for the standard deviation of max3: (4.205821626320615, 5.424570060082577)\n",
      "90% CI for the standard deviation of mean3: (3.462580983901593, 4.482105727474811)\n",
      "90% CI for the standard deviation of median3: (3.4154626810355926, 4.51783042129198)\n",
      "90% CI for the standard deviation of std_dev3: (0.762930190189586, 1.12581023991698)\n",
      "90% CI for the standard deviation of 1st_quartile3: (3.610934516472425, 4.680794380583304)\n",
      "90% CI for the standard deviation of 3rd_quartile3: (3.522236371817969, 4.657673625117397)\n",
      "90% CI for the standard deviation of min4: (0.0, 0.0)\n",
      "90% CI for the standard deviation of max4: (1.965563863940038, 2.373884886793408)\n",
      "90% CI for the standard deviation of mean4: (1.0778125512772498, 1.2213684123793558)\n",
      "90% CI for the standard deviation of median4: (1.0584318931187975, 1.2012535082610445)\n",
      "90% CI for the standard deviation of std_dev4: (0.42092716943632535, 0.48663116382542176)\n",
      "90% CI for the standard deviation of 1st_quartile4: (0.7761031361156331, 0.8926469399306483)\n",
      "90% CI for the standard deviation of 3rd_quartile4: (1.4372775337158654, 1.6272253308967628)\n",
      "90% CI for the standard deviation of min5: (4.424544091404243, 7.401111546816086)\n",
      "90% CI for the standard deviation of max5: (4.716531151328876, 6.5611867839215)\n",
      "90% CI for the standard deviation of mean5: (4.470202502595359, 6.59836199459191)\n",
      "90% CI for the standard deviation of median5: (4.561557946571012, 6.835071321075394)\n",
      "90% CI for the standard deviation of std_dev5: (0.8142381442694719, 1.2079433582247003)\n",
      "90% CI for the standard deviation of 1st_quartile5: (4.770537567858871, 7.151011219594952)\n",
      "90% CI for the standard deviation of 3rd_quartile5: (4.296530308117116, 6.472722143967209)\n",
      "90% CI for the standard deviation of min6: (0.0, 0.07847613098768465)\n",
      "90% CI for the standard deviation of max6: (2.2385236301303286, 2.7680936993038046)\n",
      "90% CI for the standard deviation of mean6: (1.0621784135529773, 1.2168682088966742)\n",
      "90% CI for the standard deviation of median6: (0.9977007871171749, 1.1481812241912588)\n",
      "90% CI for the standard deviation of std_dev6: (0.4769020319315461, 0.5438309773404042)\n",
      "90% CI for the standard deviation of 1st_quartile6: (0.6923294340056091, 0.80934352253819)\n",
      "90% CI for the standard deviation of 3rd_quartile6: (1.4130037511005415, 1.5989855769813428)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for feature, ci in bootstrap_intervals.items():\n",
    "    print(f\"90% CI for the standard deviation of {feature}: {ci}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean: It provides the central tendency in a time series relating to the \"average\" value. It gives us a hint about the overall intensity of the activity or magnitude of the signal.\r\n",
    "\n",
    "Standard Deviation \n",
    "\r\n",
    "The standard deviation represents how values deviate from the mean. It captures variability or fluctuation in the time series, which critical in distinguishing activities because of steady signals versus those withave more variation, such as sitting versus walki\n",
    "ng.\r\n",
    "Maximum or  n:\r\n",
    "\r\n",
    "The maxima/minima values of the time series capture the extremes. It gives an idea of the range and amplitude of the activity, hence distinguishing between high and low-intensity movements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Residual Sum of Squares (RSS) for cubic regression is generally lower than that for linear regression. \n",
    "\n",
    "This is because cubic regression offers more flexibility and can better capture the complexity of the training data, leading to a more accurate fit and a reduced RSS compared to linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS for linear regression is typically lower than that for cubic regression on the test data. \n",
    "\n",
    "Cubic regression tends to overfit the training data, leading to less accurate predictions on unseen test data than the more generalizable predictions from the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RSS for cubic regression is generally smaller than that for linear regression.\n",
    "\n",
    "This is because the cubic regression model has more flexibility, allowing it to fit the training data more closely, which results in a lower RSS compared to the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information provided is not enough to draw a conclusion.\n",
    "\n",
    "For test data, the RSS will depend on the nature of the relationship in the data. If the data follows a linear pattern, linear regression will likely produce a lower RSS than cubic regression. However, if the data deviates significantly from linearity, cubic regression may result in a lower RSS compared to linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.3 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.5 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refrences-\n",
    "\n",
    "https://docs.python.org/3/library/os.html#os.listdir\n",
    "\n",
    "https://docs.python.org/3/library/os.path.html#os.path.join\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.concat.html\n",
    "\n",
    "https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions\n",
    "\n",
    "https://docs.python.org/3/library/functions.html#filter\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.std.html\n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.std.html\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html\n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.std.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
